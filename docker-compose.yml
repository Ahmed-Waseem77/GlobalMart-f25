services:

  zookeeper:
    image: wurstmeister/zookeeper:latest
    container_name: zookeeper
    expose:
      - "2181"
    volumes:
      - kafka_zookeeper:/opt/zookeeper-3.4.13/data
    networks:
      kafkanet:
        ipv4_address: 172.25.0.11

  kafka1:
    image: wurstmeister/kafka:2.12-2.2.0
    container_name: kafka1
    command: [start-kafka.sh]
    expose:
      - "8080"
      - "9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.25.0.12
      KAFKA_ZOOKEEPER_CONNECT: 172.25.0.11:2181
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_OPTS: -javaagent:/prometheus/jmx_prometheus_javaagent-0.3.1.jar=8080:/prometheus/kafka-0-8-2.yml 
    volumes:
      - ./kafka/prometheus:/prometheus
      - kafka_kafka1:/opt/kafka_2.12-2.2.0/logs
    networks:
      kafkanet:
        ipv4_address: 172.25.0.12
    depends_on:
      - "zookeeper"

  kafka2:
    image: wurstmeister/kafka:2.12-2.2.0
    container_name: kafka2
    command: [start-kafka.sh]
    expose:
      - "8080"
      - "9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.25.0.13
      KAFKA_ZOOKEEPER_CONNECT: 172.25.0.11:2181
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_OPTS: -javaagent:/prometheus/jmx_prometheus_javaagent-0.3.1.jar=8080:/prometheus/kafka-0-8-2.yml 
    volumes:
      - ./kafka/prometheus:/prometheus
      - kafka_kafka2:/opt/kafka_2.12-2.2.0/logs
    depends_on:
      - "zookeeper"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.13

  kafka_manager:
    image: hlebalbau/kafka-manager:1.3.3.18
    container_name: kafka_manager
    expose:
      - "9000"
    environment:
      ZK_HOSTS: "172.25.0.11:2181"
      APPLICATION_SECRET: "random-secret"
    command: -Dpidfile.path=/dev/null
    depends_on:
      - "zookeeper"
      - "kafka1"
      - "kafka2"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.14

  prometheus:
    image: prom/prometheus:v2.8.1
    container_name: prometheus
    expose:
      - "9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./prometheus/flink.rules.yml:/etc/prometheus/flink.rules.yml
    depends_on:
      - "zookeeper"
      - "kafka1"
      - "kafka2"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.15

  grafana:
    image: grafana/grafana:6.1.1
    container_name: grafana
    expose:
      - "3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=password
    volumes:
      - ./grafana/provisioning/:/etc/grafana/provisioning/
    depends_on:
      - "prometheus"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.16

  jupyter:
    image: jupyter/pyspark-notebook:latest
    container_name: jupyter
    user: root
    ports:
      - "8888:8888"
      - "4041:4040"
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - SPARK_MASTER=spark://spark-master:7077
      - NB_USER=admin
      - CHOWN_HOME=yes
    command: start-notebook.sh --NotebookApp.token='password'
    volumes:
      - ./jupyter/notebooks:/home/admin/work
      - ./kafka/prometheus:/prometheus
    networks:
      kafkanet:
        ipv4_address: 172.25.0.19

  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    ports:
      - "8081:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - "SPARK_DAEMON_JAVA_OPTS=-javaagent:/prometheus/jmx_prometheus_javaagent-0.3.1.jar=7071:/prometheus/spark-jmx.yml"
    volumes:
      - ./kafka/prometheus:/prometheus
    networks:
      kafkanet:
        ipv4_address: 172.25.0.20

  spark-worker:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    depends_on:
      - spark-master
    ports:
      - "8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "SPARK_DAEMON_JAVA_OPTS=-javaagent:/prometheus/jmx_prometheus_javaagent-0.3.1.jar=7071:/prometheus/spark-jmx.yml"
    volumes:
      - ./kafka/prometheus:/prometheus
    networks:
      - kafkanet

  namenode:
    image: apache/hadoop:3
    container_name: namenode
    command: ["hdfs", "namenode"]
    user: root # Required to ensure permission to write to mounted volumes
    environment:
      - HADOOP_HOME=/opt/hadoop
    volumes:
      # Mount the local config files to the container's config path
      - ./hadoop_config/core-site.xml:/opt/hadoop/etc/hadoop/core-site.xml
      - ./hadoop_config/hdfs-site.xml:/opt/hadoop/etc/hadoop/hdfs-site.xml
      # Persist data
      - ./namenode:/opt/hadoop/data/nameNode.envNn.envN
    expose:
      - "9870"
      - "8020"
    ports:
      - "9870:9870"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.22
    healthcheck:
      test: ["CMD", "sh", "-c", "curl -f http://localhost:9870/"]
      interval: 10s
      timeout: 10s
      retries: 15
      start_period: 90s

  datanode:
    image: apache/hadoop:3
    container_name: datanode
    command: ["hdfs", "datanode"]
    volumes:
      - datanode:/hadoop/dfs/data
    environment:
      - SERVICE_PRECONDITION=namenode:9870
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    depends_on:
      namenode:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9864/"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      kafkanet:
        ipv4_address: 172.25.0.23

  hbase-master:
    image: bde2020/hbase-master:1.0.0-hbase1.2.6
    container_name: hbase-master
    hostname: hbase-master
    environment:
      - HBASE_CONF_hbase_rootdir=hdfs://namenode:8020/hbase
      - HBASE_CONF_hbase_zookeeper_quorum=zookeeper
      - HBASE_CONF_hbase_zookeeper_property_clientPort=2181
      - HBASE_CONF_hbase_zookeeper_property_dataDir=/zookeeper
      - HBASE_MANAGES_ZK=false
    expose:
      - "16000"
      - "16010"
    ports:
      - "16010:16010"
    depends_on:
      namenode:
        condition: service_healthy
      datanode:
        condition: service_started
      zookeeper:
        condition: service_started
    networks:
      kafkanet:
        ipv4_address: 172.25.0.24

  hbase-regionserver:
    image: bde2020/hbase-regionserver:1.0.0-hbase1.2.6
    container_name: hbase-regionserver
    hostname: hbase-regionserver
    environment:
      - HBASE_CONF_hbase_rootdir=hdfs://namenode:8020/hbase
      - HBASE_CONF_hbase_zookeeper_quorum=zookeeper
      - HBASE_CONF_hbase_zookeeper_property_clientPort=2181
      - HBASE_CONF_hbase_zookeeper_property_dataDir=/zookeeper
      - HBASE_CONF_hbase_master=hbase-master:16000
      - HBASE_MANAGES_ZK=false
    expose:
      - "16020"
      - "16030"
    depends_on:
      - hbase-master
    networks:
      - kafkanet

  hbase-thrift:
    image: bde2020/hbase-master:1.0.0-hbase1.2.6
    container_name: hbase-thrift
    hostname: hbase-thrift
    command: /opt/hbase-1.2.6/bin/hbase thrift start -p 9091
    environment:
      - HBASE_CONF_hbase_rootdir=hdfs://namenode:8020/hbase
      - HBASE_CONF_hbase_zookeeper_quorum=zookeeper
      - HBASE_CONF_hbase_zookeeper_property_clientPort=2181
      - HBASE_CONF_hbase_zookeeper_property_dataDir=/zookeeper
      - HBASE_MANAGES_ZK=false
    expose:
      - "9091"
    ports:
      - "9091:9091"
    depends_on:
      - hbase-master
      - hbase-regionserver
    networks:
      kafkanet:
        ipv4_address: 172.25.0.25

networks:
  kafkanet:
    name: kafkanet
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.25.0.0/16
          gateway: 172.25.0.1

volumes:
  kafka_zookeeper:
  kafka_kafka1:
  kafka_kafka2:
  namenode:
  datanode:

