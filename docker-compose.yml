version: "2.1"
services:

  zookeeper:
    image: wurstmeister/zookeeper:latest
    container_name: zookeeper
    expose:
      - "2181"
    volumes:
      - kafka_zookeeper:/opt/zookeeper-3.4.13/data
    networks:
      kafkanet:
        ipv4_address: 172.25.0.11

  kafka1:
    image: wurstmeister/kafka:2.12-2.2.0
    container_name: kafka1
    command: [start-kafka.sh]
    expose:
      - "8080"
      - "9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.25.0.12
      KAFKA_ZOOKEEPER_CONNECT: 172.25.0.11:2181
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_OPTS: -javaagent:/prometheus/jmx_prometheus_javaagent-0.3.1.jar=8080:/prometheus/kafka-0-8-2.yml 
    volumes:
      - ./kafka/prometheus:/prometheus
      - kafka_kafka1:/opt/kafka_2.12-2.2.0/logs
    networks:
      kafkanet:
        ipv4_address: 172.25.0.12
    depends_on:
      - "zookeeper"

  kafka2:
    image: wurstmeister/kafka:2.12-2.2.0
    container_name: kafka2
    command: [start-kafka.sh]
    expose:
      - "8080"
      - "9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.25.0.13
      KAFKA_ZOOKEEPER_CONNECT: 172.25.0.11:2181
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_OPTS: -javaagent:/prometheus/jmx_prometheus_javaagent-0.3.1.jar=8080:/prometheus/kafka-0-8-2.yml 
    volumes:
      - ./kafka/prometheus:/prometheus
      - kafka_kafka2:/opt/kafka_2.12-2.2.0/logs
    depends_on:
      - "zookeeper"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.13

  kafka_manager:
    image: hlebalbau/kafka-manager:1.3.3.18
    container_name: kafka_manager
    expose:
      - "9000"
    environment:
      ZK_HOSTS: "172.25.0.11:2181"
      APPLICATION_SECRET: "random-secret"
    command: -Dpidfile.path=/dev/null
    depends_on:
      - "zookeeper"
      - "kafka1"
      - "kafka2"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.14

  prometheus:
    image: prom/prometheus:v2.8.1
    container_name: prometheus
    expose:
      - "9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./prometheus/flink.rules.yml:/etc/prometheus/flink.rules.yml
    depends_on:
      - "zookeeper"
      - "kafka1"
      - "kafka2"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.15

  grafana:
    image: grafana/grafana:6.1.1
    container_name: grafana
    expose:
      - "3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=password
    volumes:
      - ./grafana/provisioning/:/etc/grafana/provisioning/
    depends_on:
      - "prometheus"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.16

  jupyter:
    image: jupyter/pyspark-notebook:latest
    container_name: jupyter
    user: root
    ports:
      - "8888:8888"
      - "4041:4040"
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - SPARK_MASTER=spark://spark-master:7077
      - NB_USER=admin
      - CHOWN_HOME=yes
    command: start-notebook.sh --NotebookApp.token='password'
    volumes:
      - ./jupyter/notebooks:/home/admin/work
      - ./kafka/prometheus:/prometheus
    networks:
      kafkanet:
        ipv4_address: 172.25.0.19


  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    ports:
      - "8081:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - "SPARK_DAEMON_JAVA_OPTS=-javaagent:/prometheus/jmx_prometheus_javaagent-0.3.1.jar=7071:/prometheus/spark-jmx.yml"
    volumes:
      - ./kafka/prometheus:/prometheus
    networks:
      kafkanet:
        ipv4_address: 172.25.0.20

  spark-worker:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    depends_on:
      - spark-master
    ports:
      - "8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "SPARK_DAEMON_JAVA_OPTS=-javaagent:/prometheus/jmx_prometheus_javaagent-0.3.1.jar=7071:/prometheus/spark-jmx.yml"
    volumes:
      - ./kafka/prometheus:/prometheus
    networks:
      - kafkanet

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    volumes:
      - namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    expose:
      - "9870"
      - "8020"
    ports:
      - "9870:9870"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.22

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    volumes:
      - /hadoop/dfs/data
    environment:
      - SERVICE_PRECONDITION=namenode:9870
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    depends_on:
      - namenode
    networks:
      - kafkanet

  hbase-master:
    image: bde2020/hbase-master:1.0.0-hbase1.2.6
    container_name: hbase-master
    environment:
      - HBASE_CONF_hbase_rootdir=hdfs://namenode:8020/hbase
      - HBASE_CONF_hbase_zookeeper_quorum=zookeeper
      - HBASE_CONF_hbase_zookeeper_property_clientPort=2181
    expose:
      - "16000"
      - "16010"
    ports:
      - "16010:16010"
    depends_on:
      - namenode
      - datanode
      - zookeeper
    networks:
      kafkanet:
        ipv4_address: 172.25.0.24

  hbase-regionserver:
    image: bde2020/hbase-regionserver:1.0.0-hbase1.2.6
    environment:
      - HBASE_CONF_hbase_rootdir=hdfs://namenode:8020/hbase
      - HBASE_CONF_hbase_zookeeper_quorum=zookeeper
      - HBASE_CONF_hbase_zookeeper_property_clientPort=2181
      - HBASE_MANAGES_ZK=false
    expose:
      - "16020"
      - "16030"
    depends_on:
      - hbase-master
    networks:
      - kafkanet

networks:
  kafkanet:
    name: kafkanet
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.25.0.0/16
          gateway: 172.25.0.1

volumes:
  kafka_zookeeper:
  kafka_kafka1:
  kafka_kafka2:
  namenode:

