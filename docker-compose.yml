services:
  zookeeper:
    image: wurstmeister/zookeeper:latest
    container_name: zookeeper
    expose:
      - "2181"
    volumes:
      - kafka_zookeeper:/opt/zookeeper-3.4.13/data
    networks:
      kafkanet:
        ipv4_address: 172.25.0.11

  kafka1:
    image: wurstmeister/kafka:2.12-2.2.0
    container_name: kafka1
    command: [start-kafka.sh]
    expose:
      - "8080"
      - "9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.25.0.12
      KAFKA_ZOOKEEPER_CONNECT: 172.25.0.11:2181
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_OPTS: -javaagent:/prometheus/jmx_prometheus_javaagent-0.3.1.jar=8080:/prometheus/kafka-0-8-2.yml
    volumes:
      - ./kafka/prometheus:/prometheus
      - kafka_kafka1:/opt/kafka_2.12-2.2.0/logs
    networks:
      kafkanet:
        ipv4_address: 172.25.0.12
    depends_on:
      - "zookeeper"

  kafka2:
    image: wurstmeister/kafka:2.12-2.2.0
    container_name: kafka2
    command: [start-kafka.sh]
    expose:
      - "8080"
      - "9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.25.0.13
      KAFKA_ZOOKEEPER_CONNECT: 172.25.0.11:2181
      KAFKA_ADVERTISED_PORT: 9092
      KAFKA_OPTS: -javaagent:/prometheus/jmx_prometheus_javaagent-0.3.1.jar=8080:/prometheus/kafka-0-8-2.yml
    volumes:
      - ./kafka/prometheus:/prometheus
      - kafka_kafka2:/opt/kafka_2.12-2.2.0/logs
    depends_on:
      - "zookeeper"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.13

  kafka_manager:
    image: hlebalbau/kafka-manager:1.3.3.18
    container_name: kafka_manager
    expose:
      - "9000"
    environment:
      ZK_HOSTS: "172.25.0.11:2181"
      APPLICATION_SECRET: "random-secret"
    command: -Dpidfile.path=/dev/null
    depends_on:
      - "zookeeper"
      - "kafka1"
      - "kafka2"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.14

  prometheus:
    image: prom/prometheus:v2.8.1
    container_name: prometheus
    expose:
      - "9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./prometheus/flink.rules.yml:/etc/prometheus/flink.rules.yml
    depends_on:
      - "zookeeper"
      - "kafka1"
      - "kafka2"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.15

  grafana:
    image: grafana/grafana-enterprise:12.3.0
    container_name: grafana
    expose:
      - "3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=password
      - GF_PLUGINS_PREINSTALL_SYNC=grafana-mongodb-datasource
    volumes:
      - ./grafana/provisioning/:/etc/grafana/provisioning/
    depends_on:
      - "prometheus"
    networks:
      kafkanet:
        ipv4_address: 172.25.0.16

  jupyter:
    image: jupyter/pyspark-notebook:latest
    container_name: jupyter
    user: root
    ports:
      - "8888:8888"
      - "4041:4040"
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - SPARK_MASTER=spark://spark-master:7077
      - NB_USER=admin
      - CHOWN_HOME=yes
    command: start-notebook.sh --NotebookApp.token='password'
    volumes:
      - ./jupyter/notebooks:/home/admin/work
      - ./kafka/prometheus:/prometheus
    networks:
      kafkanet:
        ipv4_address: 172.25.0.19

  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    ports:
      - "8081:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - "SPARK_DAEMON_JAVA_OPTS=-javaagent:/prometheus/jmx_prometheus_javaagent-0.3.1.jar=7071:/prometheus/spark-jmx.yml"
    volumes:
      - ./kafka/prometheus:/prometheus
    networks:
      kafkanet:
        ipv4_address: 172.25.0.20

  spark-worker:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    depends_on:
      - spark-master
    ports:
      - "8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "SPARK_DAEMON_JAVA_OPTS=-javaagent:/prometheus/jmx_prometheus_javaagent-0.3.1.jar=7071:/prometheus/spark-jmx.yml"
    volumes:
      - ./kafka/prometheus:/prometheus
    networks:
      - kafkanet

  # ==================== MongoDB Replica Set ====================
  # 3-node replica set for high availability and horizontal scaling
  # To scale: add more mongoN services following the same pattern

  mongo1:
    image: mongo:7.0
    container_name: mongo1
    hostname: mongo1
    command: ["mongod", "--replSet", "rs0", "--bind_ip_all", "--port", "27017"]
    ports:
      - "27017:27017"
    expose:
      - "27017"
    volumes:
      - mongo1_data:/data/db
      - mongo1_config:/data/configdb
    networks:
      kafkanet:
        ipv4_address: 172.25.0.30
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  mongo2:
    image: mongo:7.0
    container_name: mongo2
    hostname: mongo2
    command: ["mongod", "--replSet", "rs0", "--bind_ip_all", "--port", "27017"]
    expose:
      - "27017"
    volumes:
      - mongo2_data:/data/db
      - mongo2_config:/data/configdb
    networks:
      kafkanet:
        ipv4_address: 172.25.0.31
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  mongo3:
    image: mongo:7.0
    container_name: mongo3
    hostname: mongo3
    command: ["mongod", "--replSet", "rs0", "--bind_ip_all", "--port", "27017"]
    expose:
      - "27017"
    volumes:
      - mongo3_data:/data/db
      - mongo3_config:/data/configdb
    networks:
      kafkanet:
        ipv4_address: 172.25.0.32
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  metabase:
    image: metabase/metabase:latest
    container_name: metabase
    hostname: metabase
    ports:
      - 3000:3000
    volumes:
      - metabase_data:/metabase.db
    networks:
      kafkanet:
        ipv4_address: 172.25.0.50
    depends_on:
      - mongo1
      - mongo2
      - mongo3
    healthcheck:
      test: ["CMD", "curl", "--fail", "-I", "http://localhost:3000/api/health"]
      interval: 15s
      timeout: 5s
      retries: 5

  mongo-init:
    image: mongo:7.0
    container_name: mongo-init
    restart: "no"
    depends_on:
      mongo1:
        condition: service_healthy
      mongo2:
        condition: service_healthy
      mongo3:
        condition: service_healthy
    command: >
      mongosh --host mongo1:27017 --eval '
      rs.initiate({
        _id: "rs0",
        members: [
          { _id: 0, host: "mongo1:27017", priority: 2 },
          { _id: 1, host: "mongo2:27017", priority: 1 },
          { _id: 2, host: "mongo3:27017", priority: 1 }
        ]
      })'
    networks:
      - kafkanet

networks:
  kafkanet:
    name: kafkanet
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.25.0.0/16
          gateway: 172.25.0.1

volumes:
  kafka_zookeeper:
  kafka_kafka1:
  kafka_kafka2:
  mongo1_data:
  mongo1_config:
  mongo2_data:
  mongo2_config:
  mongo3_data:
  mongo3_config:
  metabase_data:
